initSidebarItems({"fn":[["__breakpoint","Inserts a breakpoint instruction."],["__dmb","Generates a DMB (data memory barrier) instruction or equivalent CP15 instruction."],["__dsb","Generates a DSB (data synchronization barrier) instruction or equivalent CP15 instruction."],["__isb","Generates an ISB (instruction synchronization barrier) instruction or equivalent CP15 instruction."],["__nop","Generates an unspecified no-op instruction."],["__rsr","Reads a 32-bit system register"],["__rsrp","Reads a system register containing an address"],["__wsr","Writes a 32-bit system register"],["__wsrp","Writes a system register containing an address"],["_rev_u16","Reverse the order of the bytes."],["_rev_u32","Reverse the order of the bytes."],["vabs_s16","Absolute value (wrapping)."],["vabs_s32","Absolute value (wrapping)."],["vabs_s8","Absolute value (wrapping)."],["vabsq_s16","Absolute value (wrapping)."],["vabsq_s32","Absolute value (wrapping)."],["vabsq_s8","Absolute value (wrapping)."],["vadd_f32","Vector add."],["vadd_s16","Vector add."],["vadd_s32","Vector add."],["vadd_s8","Vector add."],["vadd_u16","Vector add."],["vadd_u32","Vector add."],["vadd_u8","Vector add."],["vaddhn_high_s16","Add returning High Narrow (high half)."],["vaddhn_high_s32","Add returning High Narrow (high half)."],["vaddhn_high_s64","Add returning High Narrow (high half)."],["vaddhn_high_u16","Add returning High Narrow (high half)."],["vaddhn_high_u32","Add returning High Narrow (high half)."],["vaddhn_high_u64","Add returning High Narrow (high half)."],["vaddhn_s16","Add returning High Narrow."],["vaddhn_s32","Add returning High Narrow."],["vaddhn_s64","Add returning High Narrow."],["vaddhn_u16","Add returning High Narrow."],["vaddhn_u32","Add returning High Narrow."],["vaddhn_u64","Add returning High Narrow."],["vaddl_high_s16","Signed Add Long (vector, high half)."],["vaddl_high_s32","Signed Add Long (vector, high half)."],["vaddl_high_s8","Signed Add Long (vector, high half)."],["vaddl_high_u16","Unsigned Add Long (vector, high half)."],["vaddl_high_u32","Unsigned Add Long (vector, high half)."],["vaddl_high_u8","Unsigned Add Long (vector, high half)."],["vaddl_s16","Signed Add Long (vector)."],["vaddl_s32","Signed Add Long (vector)."],["vaddl_s8","Signed Add Long (vector)."],["vaddl_u16","Unsigned Add Long (vector)."],["vaddl_u32","Unsigned Add Long (vector)."],["vaddl_u8","Unsigned Add Long (vector)."],["vaddq_f32","Vector add."],["vaddq_s16","Vector add."],["vaddq_s32","Vector add."],["vaddq_s64","Vector add."],["vaddq_s8","Vector add."],["vaddq_u16","Vector add."],["vaddq_u32","Vector add."],["vaddq_u64","Vector add."],["vaddq_u8","Vector add."],["vaddw_high_s16","Signed Add Wide (high half)."],["vaddw_high_s32","Signed Add Wide (high half)."],["vaddw_high_s8","Signed Add Wide (high half)."],["vaddw_high_u16","Unsigned Add Wide (high half)."],["vaddw_high_u32","Unsigned Add Wide (high half)."],["vaddw_high_u8","Unsigned Add Wide (high half)."],["vaddw_s16","Signed Add Wide."],["vaddw_s32","Signed Add Wide."],["vaddw_s8","Signed Add Wide."],["vaddw_u16","Unsigned Add Wide."],["vaddw_u32","Unsigned Add Wide."],["vaddw_u8","Unsigned Add Wide."],["vand_s16","Vector bitwise and"],["vand_s32","Vector bitwise and"],["vand_s64","Vector bitwise and"],["vand_s8","Vector bitwise and"],["vand_u16","Vector bitwise and"],["vand_u32","Vector bitwise and"],["vand_u64","Vector bitwise and"],["vand_u8","Vector bitwise and"],["vandq_s16","Vector bitwise and"],["vandq_s32","Vector bitwise and"],["vandq_s64","Vector bitwise and"],["vandq_s8","Vector bitwise and"],["vandq_u16","Vector bitwise and"],["vandq_u32","Vector bitwise and"],["vandq_u64","Vector bitwise and"],["vandq_u8","Vector bitwise and"],["vceq_f32","Floating-point compare equal"],["vceq_s16","Compare bitwise Equal (vector)"],["vceq_s32","Compare bitwise Equal (vector)"],["vceq_s8","Compare bitwise Equal (vector)"],["vceq_u16","Compare bitwise Equal (vector)"],["vceq_u32","Compare bitwise Equal (vector)"],["vceq_u8","Compare bitwise Equal (vector)"],["vceqq_f32","Floating-point compare equal"],["vceqq_s16","Compare bitwise Equal (vector)"],["vceqq_s32","Compare bitwise Equal (vector)"],["vceqq_s8","Compare bitwise Equal (vector)"],["vceqq_u16","Compare bitwise Equal (vector)"],["vceqq_u32","Compare bitwise Equal (vector)"],["vceqq_u8","Compare bitwise Equal (vector)"],["vcge_f32","Floating-point compare greater than or equal"],["vcge_s16","Compare signed greater than or equal"],["vcge_s32","Compare signed greater than or equal"],["vcge_s8","Compare signed greater than or equal"],["vcge_u16","Compare unsigned greater than or equal"],["vcge_u32","Compare unsigned greater than or equal"],["vcge_u8","Compare unsigned greater than or equal"],["vcgeq_f32","Floating-point compare greater than or equal"],["vcgeq_s16","Compare signed greater than or equal"],["vcgeq_s32","Compare signed greater than or equal"],["vcgeq_s8","Compare signed greater than or equal"],["vcgeq_u16","Compare unsigned greater than or equal"],["vcgeq_u32","Compare unsigned greater than or equal"],["vcgeq_u8","Compare unsigned greater than or equal"],["vcgt_f32","Floating-point compare greater than"],["vcgt_s16","Compare signed greater than"],["vcgt_s32","Compare signed greater than"],["vcgt_s8","Compare signed greater than"],["vcgt_u16","Compare unsigned highe"],["vcgt_u32","Compare unsigned highe"],["vcgt_u8","Compare unsigned highe"],["vcgtq_f32","Floating-point compare greater than"],["vcgtq_s16","Compare signed greater than"],["vcgtq_s32","Compare signed greater than"],["vcgtq_s8","Compare signed greater than"],["vcgtq_u16","Compare unsigned highe"],["vcgtq_u32","Compare unsigned highe"],["vcgtq_u8","Compare unsigned highe"],["vcle_f32","Floating-point compare less than or equal"],["vcle_s16","Compare signed less than or equal"],["vcle_s32","Compare signed less than or equal"],["vcle_s8","Compare signed less than or equal"],["vcle_u16","Compare unsigned less than or equal"],["vcle_u32","Compare unsigned less than or equal"],["vcle_u8","Compare unsigned less than or equal"],["vcleq_f32","Floating-point compare less than or equal"],["vcleq_s16","Compare signed less than or equal"],["vcleq_s32","Compare signed less than or equal"],["vcleq_s8","Compare signed less than or equal"],["vcleq_u16","Compare unsigned less than or equal"],["vcleq_u32","Compare unsigned less than or equal"],["vcleq_u8","Compare unsigned less than or equal"],["vclt_f32","Floating-point compare less than"],["vclt_s16","Compare signed less than"],["vclt_s32","Compare signed less than"],["vclt_s8","Compare signed less than"],["vclt_u16","Compare unsigned less than"],["vclt_u32","Compare unsigned less than"],["vclt_u8","Compare unsigned less than"],["vcltq_f32","Floating-point compare less than"],["vcltq_s16","Compare signed less than"],["vcltq_s32","Compare signed less than"],["vcltq_s8","Compare signed less than"],["vcltq_u16","Compare unsigned less than"],["vcltq_u32","Compare unsigned less than"],["vcltq_u8","Compare unsigned less than"],["vcnt_p8","Population count per byte."],["vcnt_s8","Population count per byte."],["vcnt_u8","Population count per byte."],["vcntq_p8","Population count per byte."],["vcntq_s8","Population count per byte."],["vcntq_u8","Population count per byte."],["vdupq_n_s8","Duplicate vector element to vector or scalar"],["vdupq_n_u8","Duplicate vector element to vector or scalar"],["veor_s16","Vector bitwise exclusive or (vector)"],["veor_s32","Vector bitwise exclusive or (vector)"],["veor_s64","Vector bitwise exclusive or (vector)"],["veor_s8","Vector bitwise exclusive or (vector)"],["veor_u16","Vector bitwise exclusive or (vector)"],["veor_u32","Vector bitwise exclusive or (vector)"],["veor_u64","Vector bitwise exclusive or (vector)"],["veor_u8","Vector bitwise exclusive or (vector)"],["veorq_s16","Vector bitwise exclusive or (vector)"],["veorq_s32","Vector bitwise exclusive or (vector)"],["veorq_s64","Vector bitwise exclusive or (vector)"],["veorq_s8","Vector bitwise exclusive or (vector)"],["veorq_u16","Vector bitwise exclusive or (vector)"],["veorq_u32","Vector bitwise exclusive or (vector)"],["veorq_u64","Vector bitwise exclusive or (vector)"],["veorq_u8","Vector bitwise exclusive or (vector)"],["vextq_s8","Extract vector from pair of vectors"],["vextq_u8","Extract vector from pair of vectors"],["vget_lane_u64","Move vector element to general-purpose register"],["vget_lane_u8","Move vector element to general-purpose register"],["vgetq_lane_s32","Move vector element to general-purpose register"],["vgetq_lane_u16","Move vector element to general-purpose register"],["vgetq_lane_u32","Move vector element to general-purpose register"],["vgetq_lane_u64","Move vector element to general-purpose register"],["vhadd_s16","Halving add"],["vhadd_s32","Halving add"],["vhadd_s8","Halving add"],["vhadd_u16","Halving add"],["vhadd_u32","Halving add"],["vhadd_u8","Halving add"],["vhaddq_s16","Halving add"],["vhaddq_s32","Halving add"],["vhaddq_s8","Halving add"],["vhaddq_u16","Halving add"],["vhaddq_u32","Halving add"],["vhaddq_u8","Halving add"],["vhsub_s16","Signed halving subtract"],["vhsub_s32","Signed halving subtract"],["vhsub_s8","Signed halving subtract"],["vhsub_u16","Signed halving subtract"],["vhsub_u32","Signed halving subtract"],["vhsub_u8","Signed halving subtract"],["vhsubq_s16","Signed halving subtract"],["vhsubq_s32","Signed halving subtract"],["vhsubq_s8","Signed halving subtract"],["vhsubq_u16","Signed halving subtract"],["vhsubq_u32","Signed halving subtract"],["vhsubq_u8","Signed halving subtract"],["vld1_dup_f32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_p16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_p8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_s16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_s32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_s64","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_s8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_u16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_u32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_u64","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_u8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_lane_f32","Load one single-element structure to one lane of one register."],["vld1_lane_p16","Load one single-element structure to one lane of one register."],["vld1_lane_p8","Load one single-element structure to one lane of one register."],["vld1_lane_s16","Load one single-element structure to one lane of one register."],["vld1_lane_s32","Load one single-element structure to one lane of one register."],["vld1_lane_s64","Load one single-element structure to one lane of one register."],["vld1_lane_s8","Load one single-element structure to one lane of one register."],["vld1_lane_u16","Load one single-element structure to one lane of one register."],["vld1_lane_u32","Load one single-element structure to one lane of one register."],["vld1_lane_u64","Load one single-element structure to one lane of one register."],["vld1_lane_u8","Load one single-element structure to one lane of one register."],["vld1q_dup_f32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_p16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_p8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_s16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_s32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_s64","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_s8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_u16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_u32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_u64","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_u8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_lane_f32","Load one single-element structure to one lane of one register."],["vld1q_lane_p16","Load one single-element structure to one lane of one register."],["vld1q_lane_p8","Load one single-element structure to one lane of one register."],["vld1q_lane_s16","Load one single-element structure to one lane of one register."],["vld1q_lane_s32","Load one single-element structure to one lane of one register."],["vld1q_lane_s64","Load one single-element structure to one lane of one register."],["vld1q_lane_s8","Load one single-element structure to one lane of one register."],["vld1q_lane_u16","Load one single-element structure to one lane of one register."],["vld1q_lane_u32","Load one single-element structure to one lane of one register."],["vld1q_lane_u64","Load one single-element structure to one lane of one register."],["vld1q_lane_u8","Load one single-element structure to one lane of one register."],["vmax_f32","Maximum (vector)"],["vmax_s16","Maximum (vector)"],["vmax_s32","Maximum (vector)"],["vmax_s8","Maximum (vector)"],["vmax_u16","Maximum (vector)"],["vmax_u32","Maximum (vector)"],["vmax_u8","Maximum (vector)"],["vmaxq_f32","Maximum (vector)"],["vmaxq_s16","Maximum (vector)"],["vmaxq_s32","Maximum (vector)"],["vmaxq_s8","Maximum (vector)"],["vmaxq_u16","Maximum (vector)"],["vmaxq_u32","Maximum (vector)"],["vmaxq_u8","Maximum (vector)"],["vmin_f32","Minimum (vector)"],["vmin_s16","Minimum (vector)"],["vmin_s32","Minimum (vector)"],["vmin_s8","Minimum (vector)"],["vmin_u16","Minimum (vector)"],["vmin_u32","Minimum (vector)"],["vmin_u8","Minimum (vector)"],["vminq_f32","Minimum (vector)"],["vminq_s16","Minimum (vector)"],["vminq_s32","Minimum (vector)"],["vminq_s8","Minimum (vector)"],["vminq_u16","Minimum (vector)"],["vminq_u32","Minimum (vector)"],["vminq_u8","Minimum (vector)"],["vmovl_s16","Vector long move."],["vmovl_s32","Vector long move."],["vmovl_s8","Vector long move."],["vmovl_u16","Vector long move."],["vmovl_u32","Vector long move."],["vmovl_u8","Vector long move."],["vmovn_s16","Vector narrow integer."],["vmovn_s32","Vector narrow integer."],["vmovn_s64","Vector narrow integer."],["vmovn_u16","Vector narrow integer."],["vmovn_u32","Vector narrow integer."],["vmovn_u64","Vector narrow integer."],["vmovq_n_u8","Duplicate vector element to vector or scalar"],["vmul_f32","Multiply"],["vmul_s16","Multiply"],["vmul_s32","Multiply"],["vmul_s8","Multiply"],["vmul_u16","Multiply"],["vmul_u32","Multiply"],["vmul_u8","Multiply"],["vmulq_f32","Multiply"],["vmulq_s16","Multiply"],["vmulq_s32","Multiply"],["vmulq_s8","Multiply"],["vmulq_u16","Multiply"],["vmulq_u32","Multiply"],["vmulq_u8","Multiply"],["vmvn_p8","Vector bitwise not."],["vmvn_s16","Vector bitwise not."],["vmvn_s32","Vector bitwise not."],["vmvn_s8","Vector bitwise not."],["vmvn_u16","Vector bitwise not."],["vmvn_u32","Vector bitwise not."],["vmvn_u8","Vector bitwise not."],["vmvnq_p8","Vector bitwise not."],["vmvnq_s16","Vector bitwise not."],["vmvnq_s32","Vector bitwise not."],["vmvnq_s8","Vector bitwise not."],["vmvnq_u16","Vector bitwise not."],["vmvnq_u32","Vector bitwise not."],["vmvnq_u8","Vector bitwise not."],["vorr_s16","Vector bitwise or (immediate, inclusive)"],["vorr_s32","Vector bitwise or (immediate, inclusive)"],["vorr_s64","Vector bitwise or (immediate, inclusive)"],["vorr_s8","Vector bitwise or (immediate, inclusive)"],["vorr_u16","Vector bitwise or (immediate, inclusive)"],["vorr_u32","Vector bitwise or (immediate, inclusive)"],["vorr_u64","Vector bitwise or (immediate, inclusive)"],["vorr_u8","Vector bitwise or (immediate, inclusive)"],["vorrq_s16","Vector bitwise or (immediate, inclusive)"],["vorrq_s32","Vector bitwise or (immediate, inclusive)"],["vorrq_s64","Vector bitwise or (immediate, inclusive)"],["vorrq_s8","Vector bitwise or (immediate, inclusive)"],["vorrq_u16","Vector bitwise or (immediate, inclusive)"],["vorrq_u32","Vector bitwise or (immediate, inclusive)"],["vorrq_u64","Vector bitwise or (immediate, inclusive)"],["vorrq_u8","Vector bitwise or (immediate, inclusive)"],["vpadal_s16","Signed Add and Accumulate Long Pairwise."],["vpadal_s32","Signed Add and Accumulate Long Pairwise."],["vpadal_s8","Signed Add and Accumulate Long Pairwise."],["vpadal_u16","Unsigned Add and Accumulate Long Pairwise."],["vpadal_u32","Unsigned Add and Accumulate Long Pairwise."],["vpadal_u8","Unsigned Add and Accumulate Long Pairwise."],["vpadalq_s16","Signed Add and Accumulate Long Pairwise."],["vpadalq_s32","Signed Add and Accumulate Long Pairwise."],["vpadalq_s8","Signed Add and Accumulate Long Pairwise."],["vpadalq_u16","Unsigned Add and Accumulate Long Pairwise."],["vpadalq_u32","Unsigned Add and Accumulate Long Pairwise."],["vpadalq_u8","Unsigned Add and Accumulate Long Pairwise."],["vpadd_s16","Add pairwise."],["vpadd_s32","Add pairwise."],["vpadd_s8","Add pairwise."],["vpadd_u16","Add pairwise."],["vpadd_u32","Add pairwise."],["vpadd_u8","Add pairwise."],["vpaddl_s16","Signed Add Long Pairwise."],["vpaddl_s32","Signed Add Long Pairwise."],["vpaddl_s8","Signed Add Long Pairwise."],["vpaddl_u16","Unsigned Add Long Pairwise."],["vpaddl_u32","Unsigned Add Long Pairwise."],["vpaddl_u8","Unsigned Add Long Pairwise."],["vpaddlq_s16","Signed Add Long Pairwise."],["vpaddlq_s32","Signed Add Long Pairwise."],["vpaddlq_s8","Signed Add Long Pairwise."],["vpaddlq_u16","Unsigned Add Long Pairwise."],["vpaddlq_u32","Unsigned Add Long Pairwise."],["vpaddlq_u8","Unsigned Add Long Pairwise."],["vpmax_f32","Folding maximum of adjacent pairs"],["vpmax_s16","Folding maximum of adjacent pairs"],["vpmax_s32","Folding maximum of adjacent pairs"],["vpmax_s8","Folding maximum of adjacent pairs"],["vpmax_u16","Folding maximum of adjacent pairs"],["vpmax_u32","Folding maximum of adjacent pairs"],["vpmax_u8","Folding maximum of adjacent pairs"],["vpmin_f32","Folding minimum of adjacent pairs"],["vpmin_s16","Folding minimum of adjacent pairs"],["vpmin_s32","Folding minimum of adjacent pairs"],["vpmin_s8","Folding minimum of adjacent pairs"],["vpmin_u16","Folding minimum of adjacent pairs"],["vpmin_u32","Folding minimum of adjacent pairs"],["vpmin_u8","Folding minimum of adjacent pairs"],["vqadd_s16","Saturating add"],["vqadd_s32","Saturating add"],["vqadd_s8","Saturating add"],["vqadd_u16","Saturating add"],["vqadd_u32","Saturating add"],["vqadd_u8","Saturating add"],["vqaddq_s16","Saturating add"],["vqaddq_s32","Saturating add"],["vqaddq_s8","Saturating add"],["vqaddq_u16","Saturating add"],["vqaddq_u32","Saturating add"],["vqaddq_u8","Saturating add"],["vqmovn_u64","Unsigned saturating extract narrow."],["vqsub_s16","Saturating subtract"],["vqsub_s32","Saturating subtract"],["vqsub_s8","Saturating subtract"],["vqsub_u16","Saturating subtract"],["vqsub_u32","Saturating subtract"],["vqsub_u8","Saturating subtract"],["vqsubq_s16","Saturating subtract"],["vqsubq_s32","Saturating subtract"],["vqsubq_s8","Saturating subtract"],["vqsubq_u16","Saturating subtract"],["vqsubq_u32","Saturating subtract"],["vqsubq_u8","Saturating subtract"],["vraddhn_high_s16","Rounding Add returning High Narrow (high half)."],["vraddhn_high_s32","Rounding Add returning High Narrow (high half)."],["vraddhn_high_s64","Rounding Add returning High Narrow (high half)."],["vraddhn_high_u16","Rounding Add returning High Narrow (high half)."],["vraddhn_high_u32","Rounding Add returning High Narrow (high half)."],["vraddhn_high_u64","Rounding Add returning High Narrow (high half)."],["vraddhn_s16","Rounding Add returning High Narrow."],["vraddhn_s32","Rounding Add returning High Narrow."],["vraddhn_s64","Rounding Add returning High Narrow."],["vraddhn_u16","Rounding Add returning High Narrow."],["vraddhn_u32","Rounding Add returning High Narrow."],["vraddhn_u64","Rounding Add returning High Narrow."],["vreinterpret_u64_u32","Vector reinterpret cast operation"],["vreinterpretq_s8_u8","Vector reinterpret cast operation"],["vreinterpretq_u16_u8","Vector reinterpret cast operation"],["vreinterpretq_u32_u8","Vector reinterpret cast operation"],["vreinterpretq_u64_u8","Vector reinterpret cast operation"],["vreinterpretq_u8_s8","Vector reinterpret cast operation"],["vrev16_p8","Reversing vector elements (swap endianness)"],["vrev16_s8","Reversing vector elements (swap endianness)"],["vrev16_u8","Reversing vector elements (swap endianness)"],["vrev16q_p8","Reversing vector elements (swap endianness)"],["vrev16q_s8","Reversing vector elements (swap endianness)"],["vrev16q_u8","Reversing vector elements (swap endianness)"],["vrev32_p8","Reversing vector elements (swap endianness)"],["vrev32_s8","Reversing vector elements (swap endianness)"],["vrev32_u16","Reversing vector elements (swap endianness)"],["vrev32_u8","Reversing vector elements (swap endianness)"],["vrev32q_p8","Reversing vector elements (swap endianness)"],["vrev32q_s8","Reversing vector elements (swap endianness)"],["vrev32q_u16","Reversing vector elements (swap endianness)"],["vrev32q_u8","Reversing vector elements (swap endianness)"],["vrev64_f32","Reversing vector elements (swap endianness)"],["vrev64_p16","Reversing vector elements (swap endianness)"],["vrev64_p8","Reversing vector elements (swap endianness)"],["vrev64_s16","Reversing vector elements (swap endianness)"],["vrev64_s32","Reversing vector elements (swap endianness)"],["vrev64_s8","Reversing vector elements (swap endianness)"],["vrev64_u16","Reversing vector elements (swap endianness)"],["vrev64_u32","Reversing vector elements (swap endianness)"],["vrev64_u8","Reversing vector elements (swap endianness)"],["vrev64q_f32","Reversing vector elements (swap endianness)"],["vrev64q_p16","Reversing vector elements (swap endianness)"],["vrev64q_p8","Reversing vector elements (swap endianness)"],["vrev64q_s16","Reversing vector elements (swap endianness)"],["vrev64q_s32","Reversing vector elements (swap endianness)"],["vrev64q_s8","Reversing vector elements (swap endianness)"],["vrev64q_u16","Reversing vector elements (swap endianness)"],["vrev64q_u32","Reversing vector elements (swap endianness)"],["vrev64q_u8","Reversing vector elements (swap endianness)"],["vrhadd_s16","Rounding halving add"],["vrhadd_s32","Rounding halving add"],["vrhadd_s8","Rounding halving add"],["vrhadd_u16","Rounding halving add"],["vrhadd_u32","Rounding halving add"],["vrhadd_u8","Rounding halving add"],["vrhaddq_s16","Rounding halving add"],["vrhaddq_s32","Rounding halving add"],["vrhaddq_s8","Rounding halving add"],["vrhaddq_u16","Rounding halving add"],["vrhaddq_u32","Rounding halving add"],["vrhaddq_u8","Rounding halving add"],["vrsqrte_f32","Reciprocal square-root estimate."],["vshlq_n_u8","Shift right"],["vshrq_n_u8","Unsigned shift right"],["vsub_f32","Subtract"],["vsub_s16","Subtract"],["vsub_s32","Subtract"],["vsub_s64","Subtract"],["vsub_s8","Subtract"],["vsub_u16","Subtract"],["vsub_u32","Subtract"],["vsub_u64","Subtract"],["vsub_u8","Subtract"],["vsubq_f32","Subtract"],["vsubq_s16","Subtract"],["vsubq_s32","Subtract"],["vsubq_s64","Subtract"],["vsubq_s8","Subtract"],["vsubq_u16","Subtract"],["vsubq_u32","Subtract"],["vsubq_u64","Subtract"],["vsubq_u8","Subtract"]],"struct":[["APSR","Application Program Status Register"],["SY","Full system is the required shareability domain, reads and writes are the required access types"],["float32x2_t","ARM-specific 64-bit wide vector of two packed `f32`."],["float32x4_t","ARM-specific 128-bit wide vector of four packed `f32`."],["int16x4_t","ARM-specific 64-bit wide vector of four packed `i16`."],["int16x8_t","ARM-specific 128-bit wide vector of eight packed `i16`."],["int32x2_t","ARM-specific 64-bit wide vector of two packed `i32`."],["int32x4_t","ARM-specific 128-bit wide vector of four packed `i32`."],["int64x1_t","ARM-specific 64-bit wide vector of one packed `i64`."],["int64x2_t","ARM-specific 128-bit wide vector of two packed `i64`."],["int8x16_t","ARM-specific 128-bit wide vector of sixteen packed `i8`."],["int8x8_t","ARM-specific 64-bit wide vector of eight packed `i8`."],["int8x8x2_t","ARM-specific type containing two `int8x8_t` vectors."],["int8x8x3_t","ARM-specific type containing three `int8x8_t` vectors."],["int8x8x4_t","ARM-specific type containing four `int8x8_t` vectors."],["poly16x4_t","ARM-specific 64-bit wide vector of four packed `p16`."],["poly16x8_t","ARM-specific 128-bit wide vector of eight packed `p16`."],["poly64x1_t","ARM-specific 64-bit wide vector of one packed `p64`."],["poly64x2_t","ARM-specific 128-bit wide vector of two packed `p64`."],["poly8x16_t","ARM-specific 128-bit wide vector of sixteen packed `p8`."],["poly8x8_t","ARM-specific 64-bit wide polynomial vector of eight packed `p8`."],["poly8x8x2_t","ARM-specific type containing two `poly8x8_t` vectors."],["poly8x8x3_t","ARM-specific type containing three `poly8x8_t` vectors."],["poly8x8x4_t","ARM-specific type containing four `poly8x8_t` vectors."],["uint16x4_t","ARM-specific 64-bit wide vector of four packed `u16`."],["uint16x8_t","ARM-specific 128-bit wide vector of eight packed `u16`."],["uint32x2_t","ARM-specific 64-bit wide vector of two packed `u32`."],["uint32x4_t","ARM-specific 128-bit wide vector of four packed `u32`."],["uint64x1_t","ARM-specific 64-bit wide vector of one packed `u64`."],["uint64x2_t","ARM-specific 128-bit wide vector of two packed `u64`."],["uint8x16_t","ARM-specific 128-bit wide vector of sixteen packed `u8`."],["uint8x8_t","ARM-specific 64-bit wide vector of eight packed `u8`."],["uint8x8x2_t","ARM-specific type containing two `uint8x8_t` vectors."],["uint8x8x3_t","ARM-specific type containing three `uint8x8_t` vectors."],["uint8x8x4_t","ARM-specific type containing four `uint8x8_t` vectors."]]});